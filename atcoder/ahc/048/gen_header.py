#!/usr/bin/env python3
"""
LightGBM JSON â†’ C++ ãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«è‡ªå‹•ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
lgbm_params.json ã‹ã‚‰ param_model.h ã‚’ç”Ÿæˆã—ã€C++ã§é«˜é€Ÿæ¨è«–ã‚’å¯èƒ½ã«ã™ã‚‹

Usage:
    python gen_header.py
    â†’ param_model.h ãŒç”Ÿæˆã•ã‚Œã‚‹
"""

import json
import textwrap
import pathlib
import sys
from typing import Dict, Any, List

INPUT_JSON = "lgbm_params.json"
OUTPUT_HEADER = "param_model.h"

def load_models() -> List[Dict]:
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’JSONã‹ã‚‰èª­ã¿è¾¼ã¿"""
    try:
        with open(INPUT_JSON, 'r') as f:
            models = json.load(f)
        print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(models)} ãƒ¢ãƒ‡ãƒ«")
        return models
    except FileNotFoundError:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {INPUT_JSON} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å…ˆã« train_params.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

def extract_tree_structure(tree_info: List[Dict]) -> Dict:
    """LightGBMã®æœ¨æƒ…å ±ã‹ã‚‰æ±ºå®šæœ¨æ§‹é€ ã‚’æŠ½å‡º"""
    if not tree_info:
        return {"leaf_value": 0.0}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    # æœ€åˆã®æœ¨ã®ã¿ä½¿ç”¨ï¼ˆã‚·ãƒ³ãƒ—ãƒ«åŒ–ï¼‰
    return tree_info[0]["tree_structure"]

def generate_tree_code(node: Dict, indent: int = 4) -> str:
    """æ±ºå®šæœ¨ãƒãƒ¼ãƒ‰ã‹ã‚‰å†å¸°çš„ã«C++ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
    ind = " " * indent
    
    # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰
    if "leaf_value" in node:
        return f"{ind}return {node['leaf_value']:.6f};"
    
    # å†…éƒ¨ãƒãƒ¼ãƒ‰
    feature_id = node.get("split_feature", 0)
    threshold = node.get("threshold", 0.0)
    
    left_code = generate_tree_code(node.get("left_child", {}), indent + 4)
    right_code = generate_tree_code(node.get("right_child", {}), indent + 4)
    
    return textwrap.dedent(f"""
    {ind}if (features[{feature_id}] <= {threshold:.6f}) {{
    {left_code}
    {ind}}} else {{
    {right_code}
    {ind}}}""").strip()

def generate_prediction_function(model_id: int, model: Dict) -> str:
    """1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã™ã‚‹äºˆæ¸¬é–¢æ•°ã‚’ç”Ÿæˆ"""
    tree_structure = extract_tree_structure(model.get("tree_info", []))
    
    if not tree_structure:
        print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«{model_id}: æœ¨æ§‹é€ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        return f"""
inline double predict_{model_id}(const std::array<double, FEATURE_SIZE>& features) {{
    return {2.0 if model_id == 0 else 8.0 if model_id == 1 else 0.0}; // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
}}"""
    
    tree_code = generate_tree_code(tree_structure)
    
    return f"""
inline double predict_{model_id}(const std::array<double, FEATURE_SIZE>& features) {{
{tree_code}
}}"""

def generate_ensemble_function(num_models: int) -> str:
    """å…¨ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã™ã‚‹äºˆæ¸¬é–¢æ•°ã‚’ç”Ÿæˆ"""
    predictions = [f"predict_{i}(features)" for i in range(num_models)]
    
    return f"""
inline std::array<int, 3> predict_all_params(const std::array<double, FEATURE_SIZE>& features) {{
    // å„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®äºˆæ¸¬å€¤ã‚’å–å¾—
    double pred_L = {predictions[0] if len(predictions) > 0 else "2.0"};
    double pred_B = {predictions[1] if len(predictions) > 1 else "8.0"};
    double pred_P = {predictions[2] if len(predictions) > 2 else "0.0"};
    
    // æ•´æ•°å€¤ã«å¤‰æ›ï¼†ç¯„å›²åˆ¶é™
    int L = std::clamp(static_cast<int>(std::round(pred_L)), 1, 5);
    int B = std::clamp(static_cast<int>(std::round(pred_B)), 4, 20);
    int P = std::clamp(static_cast<int>(std::round(pred_P)), 0, 4);
    
    return {{L, B, P}};
}}"""

def generate_feature_extraction() -> str:
    """ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•°ã‚’ç”Ÿæˆ"""
    return """
inline std::array<double, FEATURE_SIZE> extract_features(
    int K, int H, int T, int D,
    const std::vector<std::array<double, 3>>& own_colors,
    const std::vector<std::array<double, 3>>& target_colors
) {
    std::array<double, FEATURE_SIZE> features = {};
    
    // åŸºæœ¬ç‰¹å¾´é‡
    features[0] = static_cast<double>(K);
    features[1] = static_cast<double>(H);
    features[2] = static_cast<double>(T);
    features[3] = static_cast<double>(D);
    
    // æ‰€æœ‰è‰²ã®çµ±è¨ˆé‡
    double own_r_sum = 0, own_g_sum = 0, own_b_sum = 0;
    for (const auto& c : own_colors) {
        own_r_sum += c[0];
        own_g_sum += c[1];
        own_b_sum += c[2];
    }
    double own_r_mean = own_r_sum / K;
    double own_g_mean = own_g_sum / K;
    double own_b_mean = own_b_sum / K;
    
    double own_r_var = 0, own_g_var = 0, own_b_var = 0;
    double own_r_min = 1.0, own_r_max = 0.0;
    double own_g_min = 1.0, own_g_max = 0.0;
    double own_b_min = 1.0, own_b_max = 0.0;
    
    for (const auto& c : own_colors) {
        own_r_var += (c[0] - own_r_mean) * (c[0] - own_r_mean);
        own_g_var += (c[1] - own_g_mean) * (c[1] - own_g_mean);
        own_b_var += (c[2] - own_b_mean) * (c[2] - own_b_mean);
        
        own_r_min = std::min(own_r_min, c[0]);
        own_r_max = std::max(own_r_max, c[0]);
        own_g_min = std::min(own_g_min, c[1]);
        own_g_max = std::max(own_g_max, c[1]);
        own_b_min = std::min(own_b_min, c[2]);
        own_b_max = std::max(own_b_max, c[2]);
    }
    
    features[4] = own_r_var / K;  // Råˆ†æ•£
    features[5] = own_g_var / K;  // Gåˆ†æ•£
    features[6] = own_b_var / K;  // Båˆ†æ•£
    features[7] = own_r_max - own_r_min;  // Rç¯„å›²
    features[8] = own_g_max - own_g_min;  // Gç¯„å›²
    features[9] = own_b_max - own_b_min;  // Bç¯„å›²
    
    // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè‰²ã®çµ±è¨ˆé‡
    double tgt_r_sum = 0, tgt_g_sum = 0, tgt_b_sum = 0;
    for (const auto& c : target_colors) {
        tgt_r_sum += c[0];
        tgt_g_sum += c[1];
        tgt_b_sum += c[2];
    }
    double tgt_r_mean = tgt_r_sum / H;
    double tgt_g_mean = tgt_g_sum / H;
    double tgt_b_mean = tgt_b_sum / H;
    
    double tgt_r_var = 0, tgt_g_var = 0, tgt_b_var = 0;
    for (const auto& c : target_colors) {
        tgt_r_var += (c[0] - tgt_r_mean) * (c[0] - tgt_r_mean);
        tgt_g_var += (c[1] - tgt_g_mean) * (c[1] - tgt_g_mean);
        tgt_b_var += (c[2] - tgt_b_mean) * (c[2] - tgt_b_mean);
    }
    
    features[10] = tgt_r_var / H;  // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆRåˆ†æ•£
    features[11] = tgt_g_var / H;  // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆGåˆ†æ•£
    features[12] = tgt_b_var / H;  // ã‚¿ãƒ¼ã‚²ãƒƒãƒˆBåˆ†æ•£
    
    // è‰²ç©ºé–“ã‚«ãƒãƒ¼ç‡
    double total_min_dist = 0.0;
    double min_dist_var = 0.0;
    
    for (const auto& tgt : target_colors) {
        double min_dist = 1e9;
        for (const auto& own : own_colors) {
            double dist = std::sqrt(
                (tgt[0] - own[0]) * (tgt[0] - own[0]) +
                (tgt[1] - own[1]) * (tgt[1] - own[1]) +
                (tgt[2] - own[2]) * (tgt[2] - own[2])
            );
            min_dist = std::min(min_dist, dist);
        }
        total_min_dist += min_dist;
    }
    
    double mean_min_dist = total_min_dist / H;
    
    for (const auto& tgt : target_colors) {
        double min_dist = 1e9;
        for (const auto& own : own_colors) {
            double dist = std::sqrt(
                (tgt[0] - own[0]) * (tgt[0] - own[0]) +
                (tgt[1] - own[1]) * (tgt[1] - own[1]) +
                (tgt[2] - own[2]) * (tgt[2] - own[2])
            );
            min_dist = std::min(min_dist, dist);
        }
        min_dist_var += (min_dist - mean_min_dist) * (min_dist - mean_min_dist);
    }
    
    features[13] = mean_min_dist;              // å¹³å‡æœ€å°è·é›¢
    features[14] = std::sqrt(min_dist_var / H); // è·é›¢ã®æ¨™æº–åå·®
    
    // ã‚³ã‚¹ãƒˆåŠ¹ç‡æŒ‡æ¨™
    features[15] = static_cast<double>(T) / static_cast<double>(H);  // ã‚¿ãƒ¼ãƒ³/ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ¯”
    features[16] = static_cast<double>(D) / static_cast<double>(T);  // ã‚³ã‚¹ãƒˆå¯†åº¦
    
    return features;
}"""

def generate_header_file(models: List[Dict]) -> str:
    """å®Œå…¨ãªãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    
    # ãƒ˜ãƒƒãƒ€éƒ¨åˆ†
    header = """#pragma once
#include <array>
#include <vector>
#include <algorithm>
#include <cmath>

// æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹è‡ªå‹•ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
// AtCoder AHC048 ç”¨
namespace ml_params {

constexpr int FEATURE_SIZE = 17;  // ç‰¹å¾´é‡æ¬¡å…ƒæ•°
"""
    
    # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬é–¢æ•°
    prediction_functions = []
    for i, model in enumerate(models):
        func = generate_prediction_function(i, model)
        prediction_functions.append(func)
    
    # çµ±åˆäºˆæ¸¬é–¢æ•°
    ensemble_func = generate_ensemble_function(len(models))
    
    # ç‰¹å¾´é‡æŠ½å‡ºé–¢æ•°
    feature_func = generate_feature_extraction()
    
    # ãƒ•ãƒƒã‚¿
    footer = """
}  // namespace ml_params

// ä½¿ç”¨ä¾‹:
// auto features = ml_params::extract_features(K, H, T, D, own_colors, target_colors);
// auto [L, B, P] = ml_params::predict_all_params(features);
"""
    
    # å…¨ä½“ã‚’çµåˆ
    full_header = header + "\n".join(prediction_functions) + ensemble_func + feature_func + footer
    
    return full_header

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸ”§ LightGBM â†’ C++ ãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ")
    print("=" * 50)
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    models = load_models()
    
    if len(models) != 3:
        print(f"âš ï¸ è­¦å‘Š: {len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼ˆæœŸå¾…å€¤: 3ï¼‰")
        print("L, B, P ã®é †ã§3ã¤ã®ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã™")
    
    # ãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    print("ğŸ—ï¸ C++ã‚³ãƒ¼ãƒ‰ç”Ÿæˆä¸­...")
    header_content = generate_header_file(models)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    pathlib.Path(OUTPUT_HEADER).write_text(header_content, encoding='utf-8')
    
    print(f"âœ… ãƒ˜ãƒƒãƒ€ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†: {OUTPUT_HEADER}")
    
    # çµ±è¨ˆæƒ…å ±
    line_count = header_content.count('\n')
    size_kb = len(header_content.encode('utf-8')) / 1024
    
    print(f"ğŸ“Š ç”Ÿæˆçµ±è¨ˆ:")
    print(f"   â€¢ è¡Œæ•°: {line_count}")
    print(f"   â€¢ ã‚µã‚¤ã‚º: {size_kb:.1f} KB")
    print(f"   â€¢ ãƒ¢ãƒ‡ãƒ«æ•°: {len(models)}")
    
    print("\nğŸ‰ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. #include \"param_model.h\" ã‚’ã‚½ãƒ«ãƒã«è¿½åŠ ")
    print("2. ml_params::predict_all_params() ã§ (L,B,P) ã‚’å–å¾—")
    print("3. ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ™‚ã« -O2 -march=native ã‚’æ¨å¥¨")

if __name__ == "__main__":
    main() 