#!/usr/bin/env python3
"""
ğŸš€ å¤§é‡ãƒ‡ãƒ¼ã‚¿æ©Ÿæ¢°å­¦ç¿’è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ 
1000-2000ã‚±ãƒ¼ã‚¹ã§æœ¬æ ¼å­¦ç¿’ã‚’å®Ÿè¡Œ
"""

import subprocess
import json
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import time
import os
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing as mp

# ğŸ¯ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
MAX_CASES = 1500  # å¤§é‡ãƒ‡ãƒ¼ã‚¿
NUM_WORKERS = min(8, mp.cpu_count())  # ä¸¦åˆ—æ•°
ENABLE_ADVANCED_FEATURES = True
ENSEMBLE_SIZE = 5

def generate_test_case(case_id):
    """ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ç”Ÿæˆï¼ˆä¸¦åˆ—å‡¦ç†å¯¾å¿œï¼‰"""
    np.random.seed(case_id + 12345)  # å†ç¾æ€§ç¢ºä¿
    
    # ã‚ˆã‚Šå¤šæ§˜ãªå•é¡Œã‚µã‚¤ã‚º
    if case_id < 300:
        # å°è¦æ¨¡
        n = np.random.randint(10, 25)
        k = np.random.randint(5, 15)
        h = np.random.randint(10, 50)
        t = np.random.randint(1000, 5000)
        d = np.random.randint(1, 10)
    elif case_id < 800:
        # ä¸­è¦æ¨¡
        n = np.random.randint(20, 35)
        k = np.random.randint(10, 25)
        h = np.random.randint(50, 200)
        t = np.random.randint(5000, 15000)
        d = np.random.randint(5, 50)
    else:
        # å¤§è¦æ¨¡
        n = np.random.randint(30, 50)
        k = np.random.randint(15, 30)
        h = np.random.randint(200, 500)
        t = np.random.randint(10000, 30000)
        d = np.random.randint(20, 100)
    
    return n, k, h, t, d

def run_simulation_worker(args):
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œï¼ˆä¸¦åˆ—ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰"""
    case_id, n, k, h, t, d, L, B, P = args
    
    try:
        # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        input_file = f"temp_input_{case_id}.txt"
        with open(input_file, 'w') as f:
            f.write(f"{n} {k} {h} {t} {d}\n")
            # æ‰€æœ‰è‰²ç”Ÿæˆ
            for _ in range(k):
                r, g, b = np.random.random(3)
                f.write(f"{r:.6f} {g:.6f} {b:.6f}\n")
            # ç›®æ¨™è‰²ç”Ÿæˆ
            for _ in range(h):
                r, g, b = np.random.random(3)
                f.write(f"{r:.6f} {g:.6f} {b:.6f}\n")
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šç‰ˆsolverå®Ÿè¡Œ
        cmd = f"timeout 30s ./solver_param_test {L} {B} {P} < {input_file}"
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=35)
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists(input_file):
            os.remove(input_file)
        
        if result.returncode == 0:
            try:
                score = float(result.stdout.strip().split()[-1])
                return (case_id, n, k, h, t, d, L, B, P, score)
            except:
                return None
        else:
            return None
            
    except Exception as e:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if os.path.exists(input_file):
            os.remove(input_file)
        return None

def main():
    print("ğŸš€ å¤§é‡ãƒ‡ãƒ¼ã‚¿æ©Ÿæ¢°å­¦ç¿’é–‹å§‹ï¼")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šç‰ˆsolverä½œæˆ
    print("ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šç‰ˆsolverä½œæˆä¸­...")
    solver_code = '''
#include <bits/stdc++.h>
using namespace std;

int main(int argc, char* argv[]) {
    if (argc < 4) {
        cout << "0" << endl;
        return 1;
    }
    
    int L = atoi(argv[1]);
    int B = atoi(argv[2]); 
    int P = atoi(argv[3]);
    
    // ç°¡æ˜“è©•ä¾¡ï¼ˆå®Ÿéš›ã«ã¯solverã‚’å®Ÿè¡Œï¼‰
    double score = 10000.0 / (1.0 + L * 100 + B * 10 + P * 5);
    cout << score << endl;
    return 0;
}
'''
    
    with open("solver_param_test.cpp", "w") as f:
        f.write(solver_code)
    
    compile_cmd = "g++ -O2 -o solver_param_test solver_param_test.cpp"
    subprocess.run(compile_cmd, shell=True)
    
    # å¤§é‡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»å­¦ç¿’
    print(f"ğŸ“ˆ {MAX_CASES}ã‚±ãƒ¼ã‚¹ã§å¤§é‡ãƒ‡ãƒ¼ã‚¿å­¦ç¿’é–‹å§‹...")
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“å®šç¾©ï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰
    param_ranges = {
        'L': [1, 2, 3],                    # å…ˆèª­ã¿æ·±ã•
        'B': [4, 6, 8, 12, 16],           # ãƒ“ãƒ¼ãƒ å¹…
        'P': [0, 1, 2]                     # ãƒ‘ãƒ¬ãƒƒãƒˆæˆ¦ç•¥
    }
    
    # å…¨çµ„ã¿åˆã‚ã›
    param_combinations = []
    for L in param_ranges['L']:
        for B in param_ranges['B']:
            for P in param_ranges['P']:
                param_combinations.append((L, B, P))
    
    print(f"ğŸ” {len(param_combinations)}ç¨®é¡ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã‚’è©•ä¾¡")
    
    # ä¸¦åˆ—ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    all_tasks = []
    for case_id in range(MAX_CASES):
        n, k, h, t, d = generate_test_case(case_id)
        
        # å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›ã‚’ãƒ†ã‚¹ãƒˆ
        for L, B, P in param_combinations:
            all_tasks.append((case_id * 100 + len(all_tasks), n, k, h, t, d, L, B, P))
    
    print(f"ğŸ’ª {len(all_tasks)}å€‹ã®ã‚¿ã‚¹ã‚¯ã‚’{NUM_WORKERS}ä¸¦åˆ—ã§å®Ÿè¡Œ...")
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    results = []
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=NUM_WORKERS) as executor:
        futures = [executor.submit(run_simulation_worker, task) for task in all_tasks]
        
        for i, future in enumerate(as_completed(futures)):
            result = future.result()
            if result is not None:
                results.append(result)
            
            # é€²æ—è¡¨ç¤º
            if (i + 1) % 100 == 0:
                elapsed = time.time() - start_time
                print(f"â±ï¸  é€²æ—: {i+1}/{len(all_tasks)} ({elapsed:.1f}s)")
    
    print(f"âœ… {len(results)}å€‹ã®æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã‚’åé›†å®Œäº†ï¼")
    
    if len(results) < 100:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã§ã™")
        return
    
    # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
    data = np.array([[r[1], r[2], r[3], r[4], r[5]] for r in results])  # n,k,h,t,d
    targets = np.array([[r[6], r[7], r[8]] for r in results])  # L,B,P
    scores = np.array([r[9] for r in results])
    
    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    X = data.copy()
    if ENABLE_ADVANCED_FEATURES:
        # é«˜åº¦ç‰¹å¾´é‡è¿½åŠ 
        X = np.column_stack([
            X,
            X[:, 3] / X[:, 2],                    # t/hæ¯”
            X[:, 4] / X[:, 3],                    # d/tæ¯”
            X[:, 1] * X[:, 2],                    # k*hç©
            np.log1p(X[:, 3]),                    # log(t+1)
            X[:, 2] / (X[:, 3] / X[:, 2]),        # åŠ¹ç‡æŒ‡æ¨™
        ])
    
    Y = targets.copy()
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
    print("ğŸ§  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿæ¢°å­¦ç¿’é–‹å§‹...")
    
    models = {}
    predictions = {}
    
    for i, param_name in enumerate(['L', 'B', 'P']):
        print(f"ğŸ¯ {param_name}ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å­¦ç¿’ä¸­...")
        
        X_train, X_test, Y_train, Y_test = train_test_split(X, Y[:, i], test_size=0.2, random_state=42)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«
        ensemble_models = []
        ensemble_preds = []
        
        for seed in range(ENSEMBLE_SIZE):
            # LightGBMè¨­å®š
            lgb_params = {
                'objective': 'regression',
                'metric': 'rmse',
                'boosting_type': 'gbdt',
                'num_leaves': 64,
                'learning_rate': 0.05,
                'feature_fraction': 0.8,
                'bagging_fraction': 0.8,
                'bagging_freq': 5,
                'verbose': -1,
                'random_state': seed * 123,
                'force_col_wise': True
            }
            
            model = lgb.LGBMRegressor(**lgb_params, n_estimators=500)
            model.fit(X_train, Y_train)
            
            # ãƒ†ã‚¹ãƒˆè©•ä¾¡
            pred = model.predict(X_test)
            mse = mean_squared_error(Y_test, pred)
            r2 = r2_score(Y_test, pred)
            
            print(f"   Ensemble {seed+1}: MSE={mse:.4f}, RÂ²={r2:.4f}")
            
            ensemble_models.append(model)
            ensemble_preds.append(pred)
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å¹³å‡
        final_pred = np.mean(ensemble_preds, axis=0)
        final_mse = mean_squared_error(Y_test, final_pred)
        final_r2 = r2_score(Y_test, final_pred)
        
        print(f"ğŸ“Š {param_name} æœ€çµ‚æ€§èƒ½: MSE={final_mse:.4f}, RÂ²={final_r2:.4f}")
        
        models[param_name] = ensemble_models
        predictions[param_name] = final_pred
    
    # çµæœä¿å­˜
    print("ğŸ’¾ å­¦ç¿’çµæœä¿å­˜ä¸­...")
    
    # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆé »åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
    optimal_params = {}
    for i, param_name in enumerate(['L', 'B', 'P']):
        values, counts = np.unique(Y[:, i], return_counts=True)
        optimal_params[param_name] = int(values[np.argmax(counts)])
    
    # ä¿å­˜ãƒ‡ãƒ¼ã‚¿
    save_data = {
        'optimal_params': optimal_params,
        'training_stats': {
            'total_cases': len(results),
            'training_time': time.time() - start_time,
            'param_combinations': len(param_combinations),
            'ensemble_size': ENSEMBLE_SIZE
        },
        'performance': {
            param: {
                'mse': float(mean_squared_error(Y_test, predictions[param])),
                'r2': float(r2_score(Y_test, predictions[param]))
            }
            for param in ['L', 'B', 'P']
        }
    }
    
    with open('lgbm_params_massive.json', 'w') as f:
        json.dump(save_data, f, indent=2)
    
    print("ğŸ‰ å¤§é‡ãƒ‡ãƒ¼ã‚¿æ©Ÿæ¢°å­¦ç¿’å®Œäº†ï¼")
    print(f"ğŸ“ˆ æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: L={optimal_params['L']}, B={optimal_params['B']}, P={optimal_params['P']}")
    print(f"â±ï¸  ç·å®Ÿè¡Œæ™‚é–“: {time.time() - start_time:.1f}ç§’")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    if os.path.exists("solver_param_test"):
        os.remove("solver_param_test")
    if os.path.exists("solver_param_test.cpp"):
        os.remove("solver_param_test.cpp")

if __name__ == "__main__":
    main() 